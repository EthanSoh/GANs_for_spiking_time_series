{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ing-luca/.local/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['concatenate']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import Input, Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53888 100\n"
     ]
    }
   ],
   "source": [
    "normalized_transactions_filepath = \"../datasets/berka_dataset/usable/normalized_transactions_100.npy\"\n",
    "\n",
    "transactions = np.load(normalized_transactions_filepath)\n",
    "np.random.shuffle(transactions)\n",
    "N, D = transactions.shape\n",
    "print(N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MinibatchDiscrimination(Layer):\n",
    "    \"\"\"Concatenates to each sample information about how different the input\n",
    "    features for that sample are from features of other samples in the same\n",
    "    minibatch, as described in Salimans et. al. (2016). Useful for preventing\n",
    "    GANs from collapsing to a single output. When using this layer, generated\n",
    "    samples and reference samples should be in separate batches.\"\"\"\n",
    "\n",
    "    def __init__(self, nb_kernels, kernel_dim, init='glorot_uniform', weights=None,\n",
    "                 W_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None, input_dim=None, **kwargs):\n",
    "        self.init = initializers.get(init)\n",
    "        self.nb_kernels = nb_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = [InputSpec(ndim=2)]\n",
    "\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_dim,)\n",
    "        super(MinibatchDiscrimination, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = [InputSpec(dtype=K.floatx(),\n",
    "                                     shape=(None, input_dim))]\n",
    "\n",
    "        self.W = self.add_weight(shape=(self.nb_kernels, input_dim, self.kernel_dim),\n",
    "            initializer=self.init,\n",
    "            name='kernel',\n",
    "            regularizer=self.W_regularizer,\n",
    "            trainable=True,\n",
    "            constraint=self.W_constraint)\n",
    "\n",
    "        # Set built to true.\n",
    "        super(MinibatchDiscrimination, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        activation = K.reshape(K.dot(x, self.W), (-1, self.nb_kernels, self.kernel_dim))\n",
    "        diffs = K.expand_dims(activation, 3) - K.expand_dims(K.permute_dimensions(activation, [1, 2, 0]), 0)\n",
    "        abs_diffs = K.sum(K.abs(diffs), axis=2)\n",
    "        minibatch_features = K.sum(K.exp(-abs_diffs), axis=2)\n",
    "#         return K.concatenate([x, minibatch_features], 1)\n",
    "        return minibatch_features\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "#         return input_shape[0], input_shape[1]+self.nb_kernels\n",
    "        return input_shape[0], self.nb_kernels\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'nb_kernels': self.nb_kernels,\n",
    "                  'kernel_dim': self.kernel_dim,\n",
    "#                   'init': self.init.__name__,\n",
    "                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n",
    "                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n",
    "                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n",
    "                  'input_dim': self.input_dim}\n",
    "        base_config = super(MinibatchDiscrimination, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     54,
     112,
     133
    ]
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, timesteps, latent_dim):\n",
    "        self._timesteps = timesteps\n",
    "        self._latent_dim = latent_dim\n",
    "\n",
    "    def build_model(self, lr):\n",
    "        optimizer = RMSprop(lr)\n",
    "\n",
    "        self._generator = self._build_generator(self._latent_dim, self._timesteps)\n",
    "#         self._generator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "        self._discriminator = self._build_discriminator(self._timesteps)\n",
    "        self._discriminator.compile(loss='binary_crossentropy', optimizer=RMSprop(0.00001))\n",
    "        \n",
    "        z = Input(shape=(self._latent_dim, ))\n",
    "        fake = self._generator(z)\n",
    "\n",
    "        for layer in self._discriminator.layers:\n",
    "            layer.trainable = False\n",
    "        self._discriminator.trainable = False\n",
    "\n",
    "        valid = self._discriminator(fake)\n",
    "\n",
    "        self._gan = Model(z, valid, 'GAN')\n",
    "\n",
    "        self._gan.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=RMSprop(0.0001))\n",
    "\n",
    "        self._gan.summary()\n",
    "        self._generator.summary()\n",
    "        self._discriminator.summary()\n",
    "        return self._gan, self._generator, self._discriminator\n",
    "\n",
    "    def _build_generator(self, noise_dim, timesteps):\n",
    "        generator_inputs = Input((latent_dim, ))\n",
    "        generated = generator_inputs\n",
    "        \n",
    "        generated = Lambda(lambda x: K.expand_dims(x))(generated)\n",
    "        while generated.shape[1] < timesteps:\n",
    "            generated = Conv1D(\n",
    "                32, 3, activation='relu', padding='same')(generated)\n",
    "            generated = UpSampling1D(2)(generated)\n",
    "        generated = Conv1D(\n",
    "            1, 3, activation='relu', padding='same')(generated)\n",
    "        generated = Lambda(lambda x: K.squeeze(x, -1))(generated)\n",
    "        generated = Dense(timesteps, activation='tanh')(generated)\n",
    "\n",
    "        generator = Model(generator_inputs, generated, 'generator')\n",
    "\n",
    "        return generator\n",
    "\n",
    "    def _build_discriminator(self, timesteps):\n",
    "        discriminator_inputs = Input((timesteps, ))\n",
    "        discriminated = discriminator_inputs\n",
    "        \n",
    "        mbd = MinibatchDiscrimination(5, 3)(discriminated)\n",
    "        mbd = Dense(1, activation='relu')(mbd)\n",
    "        \n",
    "        discriminated = Lambda(lambda x: K.expand_dims(x))(discriminated)\n",
    "        while discriminated.shape[1] > 1:\n",
    "            discriminated = Conv1D(32, 3, activation='relu', padding='same')(discriminated)\n",
    "            discriminated = MaxPooling1D(2, padding='same')(discriminated)\n",
    "        discriminated = Flatten()(discriminated)\n",
    "        discriminated = Dense(32, activation='relu')(discriminated)\n",
    "        discriminated = Dense(15, activation='relu')(discriminated)\n",
    "        discriminated = Dense(1, activation='relu')(discriminated) \n",
    "        discriminated = Concatenate()([discriminated, mbd])\n",
    "        discriminated = Dense(1, activation='sigmoid')(discriminated) \n",
    "\n",
    "        discriminator = Model(discriminator_inputs, discriminated, 'discriminator')\n",
    "        return discriminator\n",
    "\n",
    "    def train(self, batch_size, epochs, n_generator, n_discriminator, dataset,\n",
    "              img_frequency):\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        losses = [[], []]\n",
    "        for epoch in range(epochs):\n",
    "            for _ in range(n_discriminator):\n",
    "                indexes = np.random.randint(0, dataset.shape[0], half_batch)\n",
    "                batch_transactions = dataset[indexes]\n",
    "\n",
    "                noise = np.random.normal(0, 1, (half_batch, self._latent_dim))\n",
    "\n",
    "                generated_transactions = self._generator.predict(noise)\n",
    "\n",
    "                discriminator_loss_real = self._discriminator.train_on_batch(\n",
    "                    batch_transactions, np.ones((half_batch, 1)))\n",
    "                discriminator_loss_fake = self._discriminator.train_on_batch(\n",
    "                    generated_transactions, np.zeros((half_batch, 1)))\n",
    "                discriminator_loss = 0.5 * np.add(discriminator_loss_real,\n",
    "                                                  discriminator_loss_fake)\n",
    "\n",
    "            for _ in range(n_generator):\n",
    "                noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "                generator_loss = self._gan.train_on_batch(\n",
    "                    noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            losses[0].append(generator_loss)\n",
    "            losses[1].append(discriminator_loss)\n",
    "\n",
    "            print(\"%d [D loss: %f] [G loss: %f]\" % (epoch, discriminator_loss,\n",
    "                                                    generator_loss))\n",
    "\n",
    "            if epoch % img_frequency == 0:\n",
    "                self._save_imgs(epoch)\n",
    "                self._save_losses(losses)\n",
    "\n",
    "    def _save_imgs(self, epoch):\n",
    "        rows, columns = 5, 5\n",
    "        noise = np.random.normal(0, 1, (rows * columns, latent_dim))\n",
    "        generated_transactions = self._generator.predict(noise)\n",
    "\n",
    "        plt.subplots(rows, columns, figsize=(15, 5))\n",
    "        k = 1\n",
    "        for i in range(rows):\n",
    "            for j in range(columns):\n",
    "                plt.subplot(rows, columns, k)\n",
    "                plt.plot(generated_transactions[k - 1])\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.ylim(0, 1)\n",
    "                k += 1\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gan/%05d.png' % epoch)\n",
    "        plt.savefig('gan/last.png')\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_losses(losses):\n",
    "        plt.plot(losses[0])\n",
    "        plt.plot(losses[1])\n",
    "        plt.legend(['generator', 'discriminator'])\n",
    "        plt.savefig('gan/losses.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100\n",
    "batch_size = 64\n",
    "epochs = int(1e5)\n",
    "n_discriminator = 1\n",
    "n_generator = 1\n",
    "latent_dim = 2\n",
    "lr = 0.00005\n",
    "img_frequency = 250\n",
    "timesteps = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('gan'):\n",
    "    shutil.rmtree('gan')\n",
    "os.makedirs('gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 100)               28645     \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 21828     \n",
      "=================================================================\n",
      "Total params: 50,473\n",
      "Trainable params: 28,645\n",
      "Non-trainable params: 21,828\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_39 (Lambda)           (None, 2, 1)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 2, 32)             128       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_75 (UpSampling (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 4, 32)             3104      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_76 (UpSampling (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 8, 32)             3104      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_77 (UpSampling (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 16, 32)            3104      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_78 (UpSampling (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 32, 32)            3104      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_79 (UpSampling (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 64, 32)            3104      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_80 (UpSampling (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "lambda_40 (Lambda)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 28,645\n",
      "Trainable params: 28,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_48 (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 100, 1)       0           input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_179 (Conv1D)             (None, 100, 32)      128         lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling1D) (None, 50, 32)       0           conv1d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)             (None, 50, 32)       3104        max_pooling1d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling1D) (None, 25, 32)       0           conv1d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_181 (Conv1D)             (None, 25, 32)       3104        max_pooling1d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling1D) (None, 13, 32)       0           conv1d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_182 (Conv1D)             (None, 13, 32)       3104        max_pooling1d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling1D) (None, 7, 32)        0           conv1d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_183 (Conv1D)             (None, 7, 32)        3104        max_pooling1d_88[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling1D) (None, 4, 32)        0           conv1d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_184 (Conv1D)             (None, 4, 32)        3104        max_pooling1d_89[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling1D) (None, 2, 32)        0           conv1d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_185 (Conv1D)             (None, 2, 32)        3104        max_pooling1d_90[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling1D) (None, 1, 32)        0           conv1d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 32)           0           max_pooling1d_91[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 32)           1056        flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 15)           495         dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "minibatch_discrimination_13 (Mi (None, 5)            1500        input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 1)            16          dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 1)            6           minibatch_discrimination_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 2)            0           dense_78[0][0]                   \n",
      "                                                                 dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 1)            3           concatenate_13[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 43,656\n",
      "Trainable params: 21,828\n",
      "Non-trainable params: 21,828\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ing-luca/.local/lib/python3.5/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 8.115829] [G loss: 4.245936]\n",
      "1 [D loss: 8.117163] [G loss: 4.191650]\n",
      "2 [D loss: 7.886952] [G loss: 4.154172]\n",
      "3 [D loss: 7.958153] [G loss: 4.124950]\n",
      "4 [D loss: 8.122228] [G loss: 4.083753]\n",
      "5 [D loss: 7.783841] [G loss: 4.072050]\n",
      "6 [D loss: 7.652644] [G loss: 4.021445]\n",
      "7 [D loss: 7.978312] [G loss: 3.956775]\n",
      "8 [D loss: 7.884613] [G loss: 3.983658]\n",
      "9 [D loss: 7.886579] [G loss: 3.854421]\n",
      "10 [D loss: 7.658965] [G loss: 3.919488]\n",
      "11 [D loss: 7.697742] [G loss: 3.782183]\n",
      "12 [D loss: 7.896040] [G loss: 3.793311]\n",
      "13 [D loss: 7.903032] [G loss: 3.728346]\n",
      "14 [D loss: 7.900012] [G loss: 3.619027]\n",
      "15 [D loss: 8.137096] [G loss: 3.548946]\n",
      "16 [D loss: 7.995084] [G loss: 3.504474]\n",
      "17 [D loss: 8.145336] [G loss: 3.456769]\n",
      "18 [D loss: 8.140400] [G loss: 3.235947]\n",
      "19 [D loss: 7.915621] [G loss: 3.355437]\n",
      "20 [D loss: 7.831634] [G loss: 3.317924]\n",
      "21 [D loss: 7.325203] [G loss: 3.050607]\n",
      "22 [D loss: 7.717037] [G loss: 3.082629]\n",
      "23 [D loss: 7.952381] [G loss: 2.962346]\n",
      "24 [D loss: 7.772213] [G loss: 2.905617]\n",
      "25 [D loss: 7.495480] [G loss: 2.523790]\n",
      "26 [D loss: 8.000804] [G loss: 2.812534]\n",
      "27 [D loss: 7.537677] [G loss: 2.781484]\n",
      "28 [D loss: 7.961586] [G loss: 2.642968]\n",
      "29 [D loss: 7.950182] [G loss: 2.709925]\n",
      "30 [D loss: 7.839779] [G loss: 2.411901]\n",
      "31 [D loss: 8.231339] [G loss: 2.199482]\n",
      "32 [D loss: 7.969054] [G loss: 2.287380]\n",
      "33 [D loss: 7.884453] [G loss: 1.967423]\n",
      "34 [D loss: 7.288802] [G loss: 2.037699]\n",
      "35 [D loss: 7.703344] [G loss: 1.494390]\n",
      "36 [D loss: 7.929693] [G loss: 1.678076]\n",
      "37 [D loss: 8.002903] [G loss: 1.845587]\n",
      "38 [D loss: 8.011465] [G loss: 1.627057]\n",
      "39 [D loss: 8.263914] [G loss: 1.693770]\n",
      "40 [D loss: 7.991061] [G loss: 1.916679]\n",
      "41 [D loss: 7.144705] [G loss: 1.401817]\n",
      "42 [D loss: 7.994380] [G loss: 1.542374]\n",
      "43 [D loss: 8.072389] [G loss: 1.321279]\n",
      "44 [D loss: 8.253166] [G loss: 1.301462]\n",
      "45 [D loss: 8.156585] [G loss: 1.523976]\n",
      "46 [D loss: 8.201832] [G loss: 1.500612]\n",
      "47 [D loss: 7.723675] [G loss: 1.019449]\n",
      "48 [D loss: 7.884224] [G loss: 1.387386]\n",
      "49 [D loss: 7.503014] [G loss: 1.240696]\n",
      "50 [D loss: 7.928188] [G loss: 1.079724]\n",
      "51 [D loss: 8.084967] [G loss: 1.143116]\n",
      "52 [D loss: 8.167424] [G loss: 1.227971]\n",
      "53 [D loss: 7.622650] [G loss: 0.986572]\n",
      "54 [D loss: 7.623618] [G loss: 0.856602]\n",
      "55 [D loss: 8.042178] [G loss: 0.887679]\n",
      "56 [D loss: 7.773786] [G loss: 0.945227]\n",
      "57 [D loss: 8.028661] [G loss: 0.938234]\n",
      "58 [D loss: 7.947885] [G loss: 0.878951]\n",
      "59 [D loss: 7.538612] [G loss: 1.065434]\n",
      "60 [D loss: 7.957018] [G loss: 0.867184]\n",
      "61 [D loss: 7.661452] [G loss: 0.844880]\n",
      "62 [D loss: 7.830712] [G loss: 0.772016]\n",
      "63 [D loss: 7.744877] [G loss: 0.720305]\n",
      "64 [D loss: 7.949395] [G loss: 0.824021]\n",
      "65 [D loss: 8.162707] [G loss: 0.850815]\n",
      "66 [D loss: 7.870967] [G loss: 0.702342]\n",
      "67 [D loss: 8.148564] [G loss: 0.766120]\n",
      "68 [D loss: 7.832160] [G loss: 0.738773]\n",
      "69 [D loss: 8.047772] [G loss: 0.732220]\n",
      "70 [D loss: 7.543295] [G loss: 0.794206]\n",
      "71 [D loss: 8.183392] [G loss: 0.712267]\n",
      "72 [D loss: 7.934196] [G loss: 0.716125]\n",
      "73 [D loss: 7.935601] [G loss: 0.702849]\n",
      "74 [D loss: 7.755031] [G loss: 0.703004]\n",
      "75 [D loss: 7.921219] [G loss: 0.702788]\n",
      "76 [D loss: 7.836582] [G loss: 0.702756]\n",
      "77 [D loss: 7.413929] [G loss: 0.781108]\n",
      "78 [D loss: 7.989816] [G loss: 0.725482]\n",
      "79 [D loss: 6.879957] [G loss: 0.702929]\n",
      "80 [D loss: 7.515335] [G loss: 0.748387]\n",
      "81 [D loss: 6.983757] [G loss: 0.702656]\n",
      "82 [D loss: 7.233395] [G loss: 0.726939]\n",
      "83 [D loss: 7.710993] [G loss: 0.727059]\n",
      "84 [D loss: 7.482014] [G loss: 0.702997]\n",
      "85 [D loss: 7.685147] [G loss: 0.703308]\n",
      "86 [D loss: 8.096003] [G loss: 0.702946]\n",
      "87 [D loss: 8.066608] [G loss: 0.703560]\n",
      "88 [D loss: 7.219625] [G loss: 0.705325]\n",
      "89 [D loss: 7.317798] [G loss: 0.702923]\n",
      "90 [D loss: 7.274406] [G loss: 0.703070]\n",
      "91 [D loss: 8.010133] [G loss: 0.703844]\n",
      "92 [D loss: 7.545757] [G loss: 0.705817]\n",
      "93 [D loss: 6.596949] [G loss: 0.705682]\n",
      "94 [D loss: 7.628010] [G loss: 0.707866]\n",
      "95 [D loss: 6.773372] [G loss: 0.702835]\n",
      "96 [D loss: 7.049842] [G loss: 0.703147]\n",
      "97 [D loss: 7.025202] [G loss: 0.715423]\n",
      "98 [D loss: 7.249359] [G loss: 0.702782]\n",
      "99 [D loss: 7.547395] [G loss: 0.702691]\n",
      "100 [D loss: 7.770768] [G loss: 0.702951]\n",
      "101 [D loss: 6.568373] [G loss: 0.705203]\n",
      "102 [D loss: 7.238212] [G loss: 0.702696]\n",
      "103 [D loss: 6.009614] [G loss: 0.702404]\n",
      "104 [D loss: 7.222914] [G loss: 0.705805]\n",
      "105 [D loss: 7.288007] [G loss: 0.702760]\n",
      "106 [D loss: 6.536853] [G loss: 0.702548]\n",
      "107 [D loss: 5.739834] [G loss: 0.706221]\n",
      "108 [D loss: 5.348549] [G loss: 0.701945]\n",
      "109 [D loss: 5.027205] [G loss: 0.702205]\n",
      "110 [D loss: 5.896405] [G loss: 0.701824]\n",
      "111 [D loss: 5.115827] [G loss: 0.701684]\n",
      "112 [D loss: 6.464515] [G loss: 0.701659]\n",
      "113 [D loss: 4.852376] [G loss: 0.701908]\n",
      "114 [D loss: 5.135596] [G loss: 0.701655]\n",
      "115 [D loss: 4.107058] [G loss: 0.701446]\n",
      "116 [D loss: 4.787528] [G loss: 0.701142]\n",
      "117 [D loss: 6.495379] [G loss: 0.701234]\n",
      "118 [D loss: 4.338455] [G loss: 0.701136]\n",
      "119 [D loss: 4.181505] [G loss: 0.700590]\n",
      "120 [D loss: 4.394841] [G loss: 0.701126]\n",
      "121 [D loss: 4.255695] [G loss: 0.700884]\n",
      "122 [D loss: 4.400179] [G loss: 0.700916]\n",
      "123 [D loss: 4.680786] [G loss: 0.700723]\n",
      "124 [D loss: 4.517829] [G loss: 0.700157]\n",
      "125 [D loss: 3.684988] [G loss: 0.700298]\n",
      "126 [D loss: 3.469013] [G loss: 0.699831]\n",
      "127 [D loss: 3.225518] [G loss: 0.700247]\n",
      "128 [D loss: 2.788196] [G loss: 0.699221]\n",
      "129 [D loss: 3.225292] [G loss: 0.699293]\n",
      "130 [D loss: 3.964328] [G loss: 0.700002]\n",
      "131 [D loss: 2.653604] [G loss: 0.699704]\n",
      "132 [D loss: 2.529982] [G loss: 0.698758]\n",
      "133 [D loss: 2.585314] [G loss: 0.699987]\n",
      "134 [D loss: 3.322397] [G loss: 0.699014]\n",
      "135 [D loss: 2.201374] [G loss: 0.698117]\n",
      "136 [D loss: 3.243213] [G loss: 0.698744]\n",
      "137 [D loss: 2.523246] [G loss: 0.697726]\n",
      "138 [D loss: 2.315061] [G loss: 0.697808]\n",
      "139 [D loss: 1.622134] [G loss: 0.698338]\n",
      "140 [D loss: 2.046298] [G loss: 0.698271]\n",
      "141 [D loss: 1.997673] [G loss: 0.702937]\n",
      "142 [D loss: 1.920269] [G loss: 0.698002]\n",
      "143 [D loss: 2.248265] [G loss: 0.698945]\n",
      "144 [D loss: 1.063819] [G loss: 0.697306]\n",
      "145 [D loss: 1.318559] [G loss: 0.698385]\n",
      "146 [D loss: 1.324134] [G loss: 0.697583]\n",
      "147 [D loss: 1.036715] [G loss: 0.697818]\n",
      "148 [D loss: 0.946941] [G loss: 0.696976]\n",
      "149 [D loss: 2.001135] [G loss: 0.698242]\n",
      "150 [D loss: 1.315108] [G loss: 0.696442]\n",
      "151 [D loss: 1.259530] [G loss: 0.696820]\n",
      "152 [D loss: 1.228135] [G loss: 0.696631]\n",
      "153 [D loss: 1.665401] [G loss: 0.704166]\n",
      "154 [D loss: 2.216127] [G loss: 0.696666]\n",
      "155 [D loss: 1.436134] [G loss: 0.696594]\n",
      "156 [D loss: 0.982501] [G loss: 0.697786]\n",
      "157 [D loss: 1.077035] [G loss: 0.698043]\n",
      "158 [D loss: 1.197879] [G loss: 0.697543]\n",
      "159 [D loss: 1.166474] [G loss: 0.697084]\n",
      "160 [D loss: 1.090130] [G loss: 0.697087]\n",
      "161 [D loss: 1.544048] [G loss: 0.697383]\n",
      "162 [D loss: 0.849321] [G loss: 0.697712]\n",
      "163 [D loss: 1.199399] [G loss: 0.696703]\n",
      "164 [D loss: 0.949585] [G loss: 0.697074]\n",
      "165 [D loss: 0.826658] [G loss: 0.696425]\n",
      "166 [D loss: 1.200610] [G loss: 0.696248]\n",
      "167 [D loss: 1.013515] [G loss: 0.696378]\n",
      "168 [D loss: 1.414504] [G loss: 0.696215]\n",
      "169 [D loss: 0.719509] [G loss: 0.696126]\n",
      "170 [D loss: 1.412760] [G loss: 0.697465]\n",
      "171 [D loss: 0.756125] [G loss: 0.695635]\n",
      "172 [D loss: 0.899136] [G loss: 0.696933]\n",
      "173 [D loss: 0.816134] [G loss: 0.695964]\n",
      "174 [D loss: 0.709287] [G loss: 0.695954]\n",
      "175 [D loss: 0.708993] [G loss: 0.695855]\n",
      "176 [D loss: 0.709377] [G loss: 0.695184]\n",
      "177 [D loss: 0.949538] [G loss: 0.699684]\n",
      "178 [D loss: 0.754532] [G loss: 0.696449]\n",
      "179 [D loss: 0.950215] [G loss: 0.695700]\n",
      "180 [D loss: 0.777772] [G loss: 0.696406]\n",
      "181 [D loss: 0.709065] [G loss: 0.695613]\n",
      "182 [D loss: 0.709681] [G loss: 0.695515]\n",
      "183 [D loss: 0.954192] [G loss: 0.696195]\n",
      "184 [D loss: 0.709032] [G loss: 0.695295]\n",
      "185 [D loss: 0.751877] [G loss: 0.696638]\n",
      "186 [D loss: 1.029854] [G loss: 0.696407]\n",
      "187 [D loss: 0.709674] [G loss: 0.695800]\n",
      "188 [D loss: 0.709006] [G loss: 0.695879]\n",
      "189 [D loss: 0.739025] [G loss: 0.695836]\n",
      "190 [D loss: 0.711007] [G loss: 0.695534]\n",
      "191 [D loss: 0.709064] [G loss: 0.696193]\n",
      "192 [D loss: 0.709268] [G loss: 0.695929]\n",
      "193 [D loss: 0.722031] [G loss: 0.694866]\n",
      "194 [D loss: 0.951043] [G loss: 0.695839]\n",
      "195 [D loss: 0.805046] [G loss: 0.695434]\n",
      "196 [D loss: 0.709291] [G loss: 0.695801]\n",
      "197 [D loss: 0.709518] [G loss: 0.695928]\n",
      "198 [D loss: 0.709655] [G loss: 0.695930]\n",
      "199 [D loss: 0.920327] [G loss: 0.695555]\n",
      "200 [D loss: 0.709587] [G loss: 0.695433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 [D loss: 0.709485] [G loss: 0.695197]\n",
      "202 [D loss: 0.774452] [G loss: 0.695431]\n",
      "203 [D loss: 0.949939] [G loss: 0.695267]\n",
      "204 [D loss: 0.833357] [G loss: 0.695220]\n",
      "205 [D loss: 0.707921] [G loss: 0.694633]\n",
      "206 [D loss: 0.709707] [G loss: 0.695339]\n",
      "207 [D loss: 0.707737] [G loss: 0.695043]\n",
      "208 [D loss: 0.708111] [G loss: 0.694945]\n",
      "209 [D loss: 0.728167] [G loss: 0.694945]\n",
      "210 [D loss: 0.908796] [G loss: 0.694757]\n",
      "211 [D loss: 0.709076] [G loss: 0.741495]\n",
      "212 [D loss: 0.710764] [G loss: 0.694877]\n",
      "213 [D loss: 0.709513] [G loss: 0.694865]\n",
      "214 [D loss: 0.709693] [G loss: 0.697498]\n",
      "215 [D loss: 0.709177] [G loss: 0.695316]\n",
      "216 [D loss: 0.709142] [G loss: 0.694456]\n",
      "217 [D loss: 0.707636] [G loss: 0.695038]\n",
      "218 [D loss: 0.709385] [G loss: 0.696004]\n",
      "219 [D loss: 0.778611] [G loss: 0.695924]\n",
      "220 [D loss: 1.128358] [G loss: 0.696327]\n",
      "221 [D loss: 0.949130] [G loss: 0.695490]\n",
      "222 [D loss: 0.709931] [G loss: 0.695129]\n",
      "223 [D loss: 0.708718] [G loss: 0.695001]\n",
      "224 [D loss: 0.709543] [G loss: 0.695419]\n",
      "225 [D loss: 0.709052] [G loss: 0.695279]\n",
      "226 [D loss: 0.708501] [G loss: 0.695759]\n",
      "227 [D loss: 0.709181] [G loss: 0.696362]\n",
      "228 [D loss: 0.709677] [G loss: 0.695778]\n",
      "229 [D loss: 0.709197] [G loss: 0.695596]\n",
      "230 [D loss: 0.691926] [G loss: 0.695984]\n",
      "231 [D loss: 0.709335] [G loss: 0.694816]\n",
      "232 [D loss: 0.708976] [G loss: 0.695251]\n",
      "233 [D loss: 0.708817] [G loss: 0.696488]\n",
      "234 [D loss: 0.709031] [G loss: 0.695969]\n",
      "235 [D loss: 0.949859] [G loss: 0.697015]\n",
      "236 [D loss: 0.709534] [G loss: 0.696109]\n",
      "237 [D loss: 0.708337] [G loss: 0.695341]\n",
      "238 [D loss: 0.709016] [G loss: 0.695694]\n",
      "239 [D loss: 0.709719] [G loss: 0.696432]\n",
      "240 [D loss: 0.709474] [G loss: 0.696514]\n",
      "241 [D loss: 0.708202] [G loss: 0.695252]\n",
      "242 [D loss: 0.709240] [G loss: 0.696382]\n",
      "243 [D loss: 0.902708] [G loss: 0.695649]\n",
      "244 [D loss: 0.705682] [G loss: 0.695608]\n",
      "245 [D loss: 0.709426] [G loss: 0.696744]\n",
      "246 [D loss: 0.708853] [G loss: 0.695988]\n",
      "247 [D loss: 0.709164] [G loss: 0.707908]\n",
      "248 [D loss: 0.708592] [G loss: 0.696110]\n",
      "249 [D loss: 0.949316] [G loss: 0.696557]\n",
      "250 [D loss: 0.708695] [G loss: 0.696390]\n",
      "251 [D loss: 0.708619] [G loss: 0.696353]\n",
      "252 [D loss: 0.708546] [G loss: 0.697106]\n",
      "253 [D loss: 0.708788] [G loss: 0.696905]\n",
      "254 [D loss: 0.797278] [G loss: 0.695878]\n",
      "255 [D loss: 0.708511] [G loss: 0.695632]\n",
      "256 [D loss: 0.708891] [G loss: 0.696286]\n",
      "257 [D loss: 0.709513] [G loss: 0.696804]\n",
      "258 [D loss: 0.709202] [G loss: 0.696134]\n",
      "259 [D loss: 0.707872] [G loss: 0.697188]\n",
      "260 [D loss: 0.708789] [G loss: 0.696318]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-7f5cf9f70288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-a3dec9e2d939>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch_size, epochs, n_generator, n_discriminator, dataset, img_frequency)\u001b[0m\n\u001b[1;32m     89\u001b[0m                     batch_transactions, np.ones((half_batch, 1)))\n\u001b[1;32m     90\u001b[0m                 discriminator_loss_fake = self._discriminator.train_on_batch(\n\u001b[0;32m---> 91\u001b[0;31m                     generated_transactions, np.zeros((half_batch, 1)))\n\u001b[0m\u001b[1;32m     92\u001b[0m                 discriminator_loss = 0.5 * np.add(discriminator_loss_real,\n\u001b[1;32m     93\u001b[0m                                                   discriminator_loss_fake)\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan = GAN(timesteps, latent_dim)\n",
    "gan.build_model(lr)\n",
    "gan.train(batch_size, epochs, n_generator, n_discriminator, transactions, img_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
