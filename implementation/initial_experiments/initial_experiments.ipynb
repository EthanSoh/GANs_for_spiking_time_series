{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from keras import Input, Model, Sequential\n",
    "from keras.layers import Lambda, LSTM, RepeatVector, Dense, TimeDistributed, Bidirectional, concatenate,\\\n",
    "Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_filepath, timesteps=100, rescale=True):\n",
    "    def split_data(dataset, timesteps):\n",
    "        D = dataset.shape[1]\n",
    "        if D < timesteps:\n",
    "            return None\n",
    "        elif D == timesteps:\n",
    "            return dataset\n",
    "        else:\n",
    "            splitted_data, remaining_data = np.hsplit(dataset, [timesteps])\n",
    "            remaining_data = split_data(remaining_data, timesteps)\n",
    "            if remaining_data is not None:\n",
    "                return np.vstack([splitted_data, remaining_data])\n",
    "            return splitted_data\n",
    "\n",
    "    data = np.load(data_filepath)\n",
    "    if rescale:\n",
    "        percentile_1 = np.percentile(data, 1)\n",
    "        percentile_99 = np.percentile(data, 99)\n",
    "        data[data < percentile_1] = percentile_1\n",
    "        data[data > percentile_99] = percentile_99\n",
    "        data = MinMaxScaler(feature_range=(-1, 1)).fit_transform(data)\n",
    "    if timesteps > 0:\n",
    "        data = split_data(data, timesteps)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "balances_filepath = \"../../datasets/berka_dataset/parsed/balances.npy\"\n",
    "transactions_filepath = \"../../datasets/berka_dataset/parsed/transactions.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 30)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = 30\n",
    "transactions = get_data(transactions_filepath, timesteps=timesteps, rescale=True)\n",
    "np.random.shuffle(transactions)\n",
    "transactions = transactions[:10000]\n",
    "transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 1000\n",
    "loss = 'mse'\n",
    "latent_dim = 10\n",
    "lstm_dim = 64\n",
    "optimizer = Adam(lr, epsilon=1e-08, amsgrad=True, clipnorm=1.0)\n",
    "\n",
    "indexes = np.random.choice(transactions.shape[0], 16, replace=False)\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0.00005, patience=10, verbose=0, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(10, 4, figsize=(15, 8))\n",
    "for i, index in enumerate(range(0, 4000, 100)):\n",
    "    plt.subplot(10, 4, i+1)\n",
    "    plt.plot(transactions[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(autoencoder, indexes, data, reverse=False):\n",
    "    plt.subplots(4, 4, figsize=(15, 5))\n",
    "    for i, index in enumerate(indexes):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.plot(data[index])\n",
    "        if reverse:\n",
    "            plt.plot((autoencoder.predict(data[index:index+1]).T)[::-1])\n",
    "        else:\n",
    "            plt.plot(autoencoder.predict(data[index:index+1]).T)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.ylim(-1, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def train_autoencoder(autoencoder, inputs, outputs):\n",
    "    autoencoder.summary()\n",
    "    autoencoder.fit(inputs, outputs, epochs=epochs, validation_split=validation_split, callbacks=[early_stopping, reduce_lr])\n",
    "    plot_predictions(autoencoder, indexes, transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense-Dense autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_dense_autoencoder(timesteps, latent_dim, loss, lr):\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Dense(latent_dim, input_shape=(timesteps,), activation='tanh'))\n",
    "    autoencoder.add(Dense(timesteps, activation='tanh'))\n",
    "    autoencoder.compile(loss=loss, optimizer=optimizer)\n",
    "    return autoencoder\n",
    "\n",
    "dense_dense_autoencoder = get_dense_dense_autoencoder(timesteps, latent_dim, loss, lr)\n",
    "train_autoencoder(dense_dense_autoencoder, transactions, transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-Dense autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_dense_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr):\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Lambda(lambda x: K.expand_dims(x), input_shape=(timesteps,)))\n",
    "    autoencoder.add(LSTM(lstm_dim, return_sequences = False))\n",
    "    autoencoder.add(Dense(latent_dim, activation='tanh'))\n",
    "    autoencoder.add(Dense(timesteps, activation='tanh'))\n",
    "    \n",
    "    autoencoder.compile(loss=loss, optimizer=optimizer)\n",
    "    return autoencoder\n",
    "\n",
    "lstm_dense_autoencoder = get_lstm_dense_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr)\n",
    "train_autoencoder(lstm_dense_autoencoder, transactions, transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense-LSTM autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_lstm_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr):\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Dense(latent_dim, activation='tanh', input_shape=(timesteps,)))\n",
    "    autoencoder.add(RepeatVector(timesteps))\n",
    "    autoencoder.add(LSTM(lstm_dim, return_sequences=True))\n",
    "    autoencoder.add(TimeDistributed(Dense(1, activation='tanh')))\n",
    "    autoencoder.add(Lambda(lambda x: K.squeeze(x, -1)))\n",
    "    \n",
    "    autoencoder.compile(loss=loss, optimizer=optimizer)\n",
    "    return autoencoder\n",
    "\n",
    "dense_lstm_autoencoder = get_dense_lstm_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr)\n",
    "train_autoencoder(lstm_dense_autoencoder, transactions, transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-LSTM autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_lstm_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr):\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Lambda(lambda x: K.expand_dims(x), input_shape=(timesteps,)))\n",
    "    autoencoder.add(LSTM(lstm_dim, return_sequences = False))\n",
    "    autoencoder.add(Dense(latent_dim, activation='tanh'))\n",
    "    autoencoder.add(RepeatVector(timesteps))\n",
    "    autoencoder.add(LSTM(lstm_dim, return_sequences=True))\n",
    "    autoencoder.add(TimeDistributed(Dense(1, activation='tanh')))\n",
    "    autoencoder.add(Lambda(lambda x: K.squeeze(x, -1)))\n",
    "    \n",
    "    autoencoder.compile(loss=loss, optimizer=optimizer)\n",
    "    return autoencoder\n",
    "\n",
    "lstm_lstm_autoencoder = get_lstm_lstm_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr)\n",
    "train_autoencoder(lstm_dense_autoencoder, transactions, transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLSTM-BLSTM autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blstm_blstm_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr=0.001):\n",
    "    model_inputs = Input((timesteps,))\n",
    "    encoder = Lambda(lambda x: K.expand_dims(x))(model_inputs)\n",
    "\n",
    "    model_inputs_2 = Input((timesteps,))\n",
    "    steps = Lambda(lambda x: K.expand_dims(x))(model_inputs_2)\n",
    "\n",
    "    encoder = Bidirectional(LSTM(lstm_dim, return_sequences = False))(encoder)\n",
    "    encoder = Dense(latent_dim, activation='tanh')(encoder)\n",
    "    encoder = RepeatVector(timesteps)(encoder)\n",
    "    encoder = concatenate([encoder, steps])\n",
    "    \n",
    "    decoder = Bidirectional(LSTM(lstm_dim, return_sequences=True))(encoder)\n",
    "    decoder = TimeDistributed(Dense(1, activation='tanh'))(decoder)\n",
    "    decoder = Lambda(lambda x: K.squeeze(x, -1))(decoder)\n",
    "    \n",
    "    autoencoder = Model([model_inputs, model_inputs_2], decoder)\n",
    "\n",
    "    autoencoder.compile(loss=loss, optimizer=optimizer)\n",
    "    return autoencoder\n",
    "\n",
    "steps = np.arange(0, 1, 1/timesteps)\n",
    "steps = np.tile(steps,(transactions.shape[0],1))\n",
    "\n",
    "blstm_blstm_autoencoder = get_blstm_blstm_autoencoder(timesteps, lstm_dim, latent_dim, loss, lr)\n",
    "train_autoencoder(lstm_dense_autoencoder, [transactions, steps], transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_141 (InputLayer)          (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_213 (Lambda)             (None, 30, 1)        0           input_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_127 (Bidirectiona (None, 128)          33792       lambda_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 10)           1290        bidirectional_127[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_142 (InputLayer)          (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_78 (RepeatVector) (None, 30, 10)       0           dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_214 (Lambda)             (None, 30, 1)        0           input_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 30, 11)       0           repeat_vector_78[0][0]           \n",
      "                                                                 lambda_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_128 (Bidirectiona (None, 30, 128)      38912       concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistri (None, 30, 1)        129         bidirectional_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_215 (Lambda)             (None, 30)           0           time_distributed_44[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 74,123\n",
      "Trainable params: 74,123\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/500\n",
      "7000/7000 [==============================] - 33s 5ms/step - loss: 0.0358 - val_loss: 0.0303\n",
      "Epoch 2/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0308 - val_loss: 0.0244\n",
      "Epoch 3/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0253 - val_loss: 0.0242\n",
      "Epoch 4/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0239 - val_loss: 0.0211\n",
      "Epoch 5/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0251 - val_loss: 0.0199\n",
      "Epoch 6/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0228 - val_loss: 0.0173\n",
      "Epoch 7/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0208 - val_loss: 0.0168\n",
      "Epoch 8/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0199 - val_loss: 0.0169\n",
      "Epoch 9/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0202 - val_loss: 0.0177\n",
      "Epoch 10/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0199 - val_loss: 0.0199\n",
      "Epoch 11/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0203 - val_loss: 0.0191\n",
      "Epoch 12/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0202 - val_loss: 0.0163\n",
      "Epoch 13/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0179 - val_loss: 0.0142\n",
      "Epoch 14/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0181 - val_loss: 0.0149\n",
      "Epoch 15/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 16/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0156 - val_loss: 0.0162\n",
      "Epoch 17/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0161 - val_loss: 0.0138\n",
      "Epoch 18/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0141 - val_loss: 0.0134\n",
      "Epoch 19/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0147 - val_loss: 0.0127\n",
      "Epoch 20/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0138 - val_loss: 0.0191\n",
      "Epoch 21/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0151 - val_loss: 0.0131\n",
      "Epoch 22/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 23/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0126 - val_loss: 0.0168\n",
      "Epoch 24/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 25/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 26/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 27/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 28/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 29/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 30/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 31/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 32/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 33/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 34/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 35/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 36/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 37/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 38/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 39/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 40/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 41/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 42/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 43/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 44/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 45/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 46/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 47/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 48/500\n",
      "7000/7000 [==============================] - 23s 3ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 49/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 50/500\n",
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 24s 3ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 52/500\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.0095"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Conv autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_conv_autoencoder(timesteps, loss, lr):\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Lambda(lambda x: K.expand_dims(x), input_shape=(timesteps,)))\n",
    "    autoencoder.add(Conv1D(32, 5, activation='tanh', padding='same'))\n",
    "    autoencoder.add(MaxPooling1D(2, padding='same'))\n",
    "    autoencoder.add(Conv1D(64, 4, activation='tanh', padding='same'))\n",
    "    autoencoder.add(MaxPooling1D(2, padding='same'))\n",
    "    autoencoder.add(Conv1D(3, 3, activation='tanh', padding='same'))\n",
    "    autoencoder.add(MaxPooling1D(2, padding='same'))\n",
    "\n",
    "    autoencoder.add(Conv1D(3, 3, activation='tanh', padding='same'))\n",
    "    autoencoder.add(UpSampling1D(2))\n",
    "    autoencoder.add(Conv1D(64, 4, activation='tanh', padding='same'))\n",
    "    autoencoder.add(UpSampling1D(2))\n",
    "    autoencoder.add(Conv1D(32, 5, activation='tanh', padding='same'))\n",
    "    autoencoder.add(UpSampling1D(2))\n",
    "    autoencoder.add(Conv1D(1, 3, activation='tanh', padding='same'))\n",
    "    autoencoder.add(Lambda(lambda x: K.squeeze(x, -1)))\n",
    "    autoencoder.compile(loss=loss, optimizer=optimizer)\n",
    "    return autoencoder\n",
    "\n",
    "conv_conv_autoencoder = get_conv_conv_autoencoder(timesteps, loss, lr)\n",
    "train_autoencoder(conv_conv_autoencoder, transactions, transactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
